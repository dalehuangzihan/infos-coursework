Q: Describe a common problem with the multiple queue priority algorithm.

In a multiple queue priority algorithm, for a task in a particular queue to be scheduled, all the higher priority queues must be empty at the point when the scheduling event occurs. This could lead to starvation for lower-level processes: some processes in lower-priority queues could starve for CPU time if some higher priority queues never become empty. This could occur when there is a large and continuous influx of high-priority tasks that each take a long time to complete.


Q: Suggest a potential solution to address the drawbacks of the multiple queue priority algorithm.
(Solution should not be any of the algorithms already discussed in lectures).

We consider instead a variation of the Linux O(1) scheduler, which resembles the multiple queue scheduling algorithm except that it instead maintains two run-queues for each priority level. For each priority level, one of the queues would contain the currently-active tasks that are waiting to be scheduled, while the other queue would contain the currently-inactive tasks that are not currently considered for scheduling.

A task from a currently-active queue is moved to the corresponding currently-inactive queue after it has been executed by the CPU for one time-slice. When all tasks in the currently-active queues have been executed for one time-slice each (rendering all the currently-active queues empty), the scheduling algorithm will switch to the currently-inactive queues and make them active (and make the previously active queues inactive). To identify the task to be scheduled next, the scheduling algorithm uses largely similar logic to that of the multiple queue priority algorithm (i.e. based on priority level) and dequeues the task from the relevant currently-active queue.

New processes are added to the currently-inactive queues, thereby ensuring that the number of tasks in the currently-active queues does not increase while the scheduling algorithm performs the scheduling. As such, when the scheduler is flooded with new high-priority tasks, these new tasks will not affect the set of tasks currently being considered by the scheduler. These new tasks would only be considered for scheduling after the CPU has executed all the current set of tasks for one time-slice each, regardless of priority. This therefore ensures that all tasks are scheduled some CPU time regardless of priority, thereby resolving the starvation problem faced in the multiple queue priority algorithm.


Q: Discuss the drawbacks of your proposed solution.

Since our proposed scheduling algorithm executes each currently-active task for only one time-slice before moving them to the corresponding currently-inactive queue, each task would have a longer turnaround time and lower throughput than before, especially when the currently-active priority queues have a large number of tasks queued up for scheduling. The reason for this is: for a given task to be executed again for another time slice after being moved to one of the currently-inactive queues, the scheduling algorithm would first have to finish scheduling all the remaining tasks in the currently-active queues before it switches to consider tasks in the currently-inactive queues for scheduling. Additionally, if many new tasks are added to the currently-inactive queues while the currently-active queues are undergoing scheduling, the total pool of tasks to be considered would increase even further, thereby exacerbating the aforementioned problems of longer turnaround time and lower throughput. Our algorithm also performs a much more context switches than the original multiple queue priority algorithm, thereby making it more computationally expensive.

This turnaround time issue could potentially be addressed by altering our proposed scheduling algorithm to finish all the tasks in the currently-active queues (instead of just running them for one time-slice each) before switching to the currently-inactive queues. New tasks would still be added to the currently-inactive queue. Although this change could potentially increase throughput, it would increase the waiting time for each task â€“ if the currently-active set of queues each have a large number of tasks enqueued, the scheduler would need to finish executing all these tasks before it can move on to those new tasks in the currently-inactive queues. This means that there would be a long waiting time between when a new task is passed to the scheduler for scheduling and when the task is actually executed. The turnaround time thus could still be long. 

Given these trade-offs, we choose to adopt the version of our algorithm that has the CPU execute a small part of every task that is passed to it in turn (sacrificing throughput), as this would help avoid the potentially undesirable situation where important tasks wait for too long before they are even considered for scheduling, by which time it might be too late.
